{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS382: Advanced Predictive Modeling</p>\n",
    "# <p style=\"text-align: center;\">Assignment 5</p>\n",
    "## <p style=\"text-align: center;\">Total points: 55</p>\n",
    "## <p style=\"text-align: center;\">Due: Tuesday, December 3rd, submitted via Canvas by 11:59 pm</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Your partner needs to be from the same section. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TA know. \n",
    "\n",
    "Please ensure that the notebook you have uploaded on Canvas is the correct one, you could download the notebook from Canvas to double check that you have submitted the correct version on your notebook.\n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name(s)\n",
    "1. \n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Bayesian Belief Network (15 pts)\n",
    "\n",
    "**Q1.1** (10pts) Consider the Bayes' Net over 4 Random Variables - $D,Z,T1,T2$ with the structure shown below, and joint probability distribution $P(D,Z,T1,T2)$. All the variables are binary with 1 representing \"true/positive\" and 0 representing \"false/negative\". \n",
    "\n",
    "![bayesnetq1.png](bayesnetq1.png)\n",
    "\n",
    "The probabilities are given below:\n",
    "\n",
    "P(D = 1) = 0.1   \n",
    "P(D = 0) = 0.9  \n",
    "\n",
    "P(Z = 1 | D = 1) = 0.7   \n",
    "P(Z = 0 | D = 1) = 0.3  \n",
    "P(Z = 1 | D = 0) = 0.8  \n",
    "P(Z = 0 | D = 0) = 0.2  \n",
    "\n",
    "P(T2 = 1 | D = 1) = 0.7           \n",
    "P(T2 = 0 | D = 1) = 0.3         \n",
    "P(T2 = 1 | D = 0) = 0.5     \n",
    "P(T2 = 0 | D = 0) = 0.5        \n",
    "\n",
    "P(T1 = 1 | D = 1, Z = 1) = 0.9         \n",
    "P(T1 = 0 | D = 1, Z = 1) = 0.1          \n",
    "P(T1 = 1 | D = 1, Z = 0) = 0.8             \n",
    "P(T1 = 0 | D = 1, Z = 0) = 0.2            \n",
    "P(T1 = 1 | D = 0, Z = 1) = 0.6           \n",
    "P(T1 = 0 | D = 0, Z = 1) = 0.4          \n",
    "P(T1 = 1 | D = 0, Z = 0) = 0.1         \n",
    "P(T1 = 0 | D = 0, Z = 0) = 0.9            \n",
    "\n",
    "\n",
    "a.(4pts) What is the probability of having disease D(D=1) and getting a positive result on test T1(T1=1)?   \n",
    "b.(3pts) What is the probability of not having disease D(D=0) and getting a positive result on test T1(T1=1)?   \n",
    "c.(3pts) What is the probability of having disease D given a positive result on test T1?   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.2**(5pts) Draw a Bayesian Network with these Random Variables - $A, B, C, D, E, F, G, H$ whose joint distribution corresponds to -\n",
    "$P(A | B,C,E) P(B | D,E) P(C | F,H) P(D | G) P(E| G,H) P(F | H) P(G) P(H)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - K-Nearest Neighbours and Ensemble (40pts)\n",
    "\n",
    "In this problem, we will continue with the Churn Prediction from the last homework. You can reuse the code for pipelines which we have provided. The data has been split into train and validation sets; please do not change this.\n",
    "\n",
    "\n",
    "1. Build K-Nearest Neighbours (KNN) models with different values of k ranging from 2 to 50. Plot how the train and validation AUROC varies with k. Report the best AUROC on the validation set and the corresponding value of k. (10 pts)\n",
    "\n",
    "    We will reuse the Naive Bayes and Logistic regression models from the previous homework.\n",
    "    \n",
    "2. Ensemble the KNN model which obtains the best AUROC on the validation set with a Naive Bayes and Logistic regression model (with parameter class_weight='balanced') by averaging the posterior probabilities. Report the validation AUROC and F1 score. (5 pts)\n",
    "\n",
    "3. Ensemble the KNN model which obtains the best AUROC on the validation set with a Naive Bayes and Logistic regression model (with parameter class_weight='balanced') by taking a majority vote. Report the validation F1 score. Explain why we cannot compute the AUROC in this setting. (5 pts)\n",
    "\n",
    "    We will now compare [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier). \n",
    "    \n",
    "4. Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to classify the data. Find the best parameters (including *n_estimators*, *max_features* and *criterion*) using [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Report the optimal parameters obtained by GridSearch. Report the confusion matrix  and [roc_auc_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) on validation data. Plot the feature importance as well. (5pts)\n",
    "5. Use [Gradient Boosting Decision Tree](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) (GBDT), and [AdaBoost](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier) for this problem. Again, find the best parameters (including *n_estimators, learning_rate,* and *max_depth (GBDT only)*), and report the confusion matrix and roc_auc_score on test data for each classifier. Also, plot the feature importance for each classifier. (10pts)\n",
    "6. Point out one advantage and one disadvantage of Random Forest compared to GBDT. (5pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.ensemble import RandomForestClassifier,\\\n",
    "GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,col):\n",
    "        self.col = col\n",
    "                \n",
    "    def transform(self, X):\n",
    "        return pd.get_dummies(X[self.col]) \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    \n",
    "# Stateless transformer for selecting a specified columns\n",
    "class DFSubsetSelector(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self,cols):\n",
    "        self.cols = cols\n",
    "        \n",
    "    def transform(self ,X):\n",
    "        return X[self.cols]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "class ConcatFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,cols,sep=\"_\"):\n",
    "        self.cols = cols\n",
    "        self.sep = sep\n",
    "                \n",
    "    def transform(self, X):\n",
    "        concat_col = self.sep.join(self.cols)\n",
    "        return X.apply(lambda x : self.sep.join([x[col] for col in self.cols]) ,axis=1).to_frame(name = concat_col)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    \n",
    "# Transformer that does min-max transform on the specified columns\n",
    "class MinMaxTransform(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self,cols=None):\n",
    "        self.cols = cols\n",
    "        self.minVec = np.zeros(len(cols))\n",
    "        self.maxVec = np.zeros(len(cols))\n",
    "       \n",
    "    def transform(self, X):\n",
    "        X[self.cols] = ((X[self.cols] - self.minVec)/(self.maxVec-self.minVec))\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.minVec = (df_train[self.cols].min())\n",
    "        self.maxVec = (df_train[self.cols].max())\n",
    "        return self\n",
    "\n",
    "df = pd.read_csv('hw5.csv', delimiter=',')\n",
    "\n",
    "#DONOT CHANGE THIS\n",
    "df_train = df.sample(frac=0.8,random_state=11)\n",
    "df_val = df.drop(df_train.index)\n",
    "\n",
    "\n",
    "X_train = df_train.drop(['Exited'],axis=1)\n",
    "y_train = df_train['Exited']\n",
    "X_val= df_val.drop(['Exited'],axis=1)\n",
    "y_val = df_val['Exited']\n",
    "\n",
    "continuous_vars = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "cat_vars = ['HasCrCard','IsActiveMember',\"Geography\", \"Gender\"] \n",
    "\n",
    "#building the data-processing pipeline\n",
    "categorical_feature_pipeline = Pipeline([\n",
    "                                       ('categorical_selector' ,DFSubsetSelector(cat_vars)),\n",
    "                                        ('onehot',OneHotEncoder(cat_vars))])\n",
    "numerical_feature_pipeline = Pipeline([\n",
    "                                       ('numerical_selector' ,DFSubsetSelector(continuous_vars)),\n",
    "                                        ('normalization',MinMaxTransform(continuous_vars))])\n",
    "all_feature_preprocessor= FeatureUnion(transformer_list=[('numerical_preprocessor', numerical_feature_pipeline),\n",
    "                                                      ('categorical_preprocessor', categorical_feature_pipeline)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
